"""
Compare the results of two A* runs.

This script takes as input two of the CSVs generated by the Rust program. The
first is the baseline, and the second is the new run. It will compare the
performance given the metrics in the CSVs.
"""

import argparse
import os

import matplotlib.pyplot as plt
import pandas as pd
import yaml


def main(args: argparse.Namespace):

    base_df = pd.read_csv(args.base)
    new_df = pd.read_csv(args.new)

    # Print statistics for the new run
    print("New Run Statistics:")
    print(f"    Mean Time (s):        {new_df['time-seconds'].mean()}")
    print(f"    Mean Path Length:     {new_df['distance'].mean()}")
    print(f"    Mean Nodes Expanded:  {new_df['stat-nodes-expanded'].mean()}")
    print(f"    Mean Nodes Generated: {new_df['stat-nodes-generated'].mean()}")
    print(f"    Mean Heuristic Calls: {new_df['stat-heuristic-calls'].mean()}")
    print(f"    Mean Heuristic Nodes:  {new_df['stat-heuristic-nodes'].mean()}")

    # Print statistics compared to the baseline
    print("\nComparison to Baseline (Mean):")
    pl = (new_df["distance"] / base_df["distance"]).mean()
    ne = (new_df["stat-nodes-expanded"] / base_df["stat-nodes-expanded"]).mean()
    ng = (new_df["stat-nodes-generated"] / base_df["stat-nodes-generated"]).mean()
    hc = (new_df["stat-heuristic-calls"] / base_df["stat-heuristic-calls"]).mean()
    hn = (new_df["stat-heuristic-nodes"] / base_df["stat-heuristic-nodes"]).mean()
    print(f"    Mean Relative Path Length:      {pl}")
    print(f"    Mean Relative Nodes Expanded:   {ne}")
    print(f"    Mean Relative Nodes Generated:  {ng}")
    print(f"    Mean Relative Heuristic Calls:  {hc}")
    print(f"    Mean Relative Heuristic Nodes:  {hn}")

    print("\nComparison to Baseline (Median):")
    pl = (new_df["distance"] / base_df["distance"]).median()
    ne = (new_df["stat-nodes-expanded"] / base_df["stat-nodes-expanded"]).median()
    ng = (new_df["stat-nodes-generated"] / base_df["stat-nodes-generated"]).median()
    hc = (new_df["stat-heuristic-calls"] / base_df["stat-heuristic-calls"]).median()
    hn = (new_df["stat-heuristic-nodes"] / base_df["stat-heuristic-nodes"]).median()
    print(f"    Median Relative Path Length:      {pl}")
    print(f"    Median Relative Nodes Expanded:   {ne}")
    print(f"    Median Relative Nodes Generated:  {ng}")
    print(f"    Median Relative Heuristic Calls:  {hc}")
    print(f"    Median Relative Heuristic Nodes:  {hn}")

    # Plot histograms of the relative performance
    for key, title in [
        ("stat-nodes-expanded", "Relative Nodes Expanded"),
        ("stat-nodes-generated", "Relative Nodes Generated"),
        ("stat-heuristic-calls", "Relative Heuristic Calls"),
        ("stat-heuristic-nodes", "Relative Heuristic Nodes"),
    ]:
        fig, ax = plt.subplots()
        ax.hist(new_df[key] / base_df[key], bins=50, density=True)
        ax.set_title(title)
        ax.set_xlabel("Ratio over Null Heuristic")
        ax.set_ylabel("Density")
        fig.savefig(os.path.join(args.output_dir, f"{key}.png"))


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Compare two A* runs.")
    parser.add_argument(
        "-c",
        "--config",
        type=argparse.FileType("r"),
        help="Path to config file",
        default="config.yaml",
    )
    parser.add_argument(
        "-o",
        "--output-dir",
        type=str,
        help="Directory to save histograms to",
        default=".",
    )
    parser.add_argument(
        "base",
        type=argparse.FileType("r"),
        help="The baseline CSV.",
    )
    parser.add_argument(
        "new",
        type=argparse.FileType("r"),
        help="The new CSV to test against baseline.",
    )

    args = parser.parse_args()
    config = yaml.safe_load(args.config)
    plt.style.use(config["plotting"]["style"])

    main(args)
